# -*- coding: utf-8 -*-
"""big-data-pyspark-sol

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1s4NVqaSd6USfvuv2KNph_a4qEByugSme
"""

!pip install pyspark

import pyspark
import numpy as np
import pandas as pd
from pyspark.sql import SparkSession
from pyspark.sql import functions as f
from pyspark.sql.types import *
import matplotlib.pyplot as plt

spark = SparkSession.builder.getOrCreate()

data = spark.read.csv(r"/content/LoansDataset.csv", header = True, inferSchema = True)

"""## **Imputation**"""

data.printSchema()

# Obtain the list of columns
columns = data.columns
columns

# Verify the columns contain null values
for c in columns:
  print(c, data.filter(f.col(c).isNull()).count())

# Credit Score and Annual Income have nulls

## Counting the number of nulls

data.filter(f.col("Loan ID").isNull()).count()

data[['Loan ID']].show()

"""# **Fix Spelling Errors and Differences**"""

data.columns

#data = data.withColumnRenamed("Years in current job", "Years in Current Job")

#data = data.withColumnRenamed("Months since last delinquent", "Months Since Last Delinquency")

data = data.withColumnsRenamed({"Years in current job": "Years in Current Job", "Months since last delinquent": "Months Since Last Delinquency"})

"""# **Remove duplicate rows in Loan ID**"""

# Verify that there are duplicates under LOan ID
data.groupby('Loan ID').count().sort('count', ascending = False).show()

data = data.withColumn('Loan ID', f.col('Loan ID').cast('string'))
data = data.drop_duplicates(subset = ['Loan ID'])

data.groupby('Bankruptcies').count().show()

data.where(data['Bankruptcies'] == 'NA').show()

data.groupby('Bankruptcies').count().sort('Bankruptcies').show()

data.groupby('Current Loan Amount').count().sort('Current Loan Amount', ascending = False).show()

"""# **Fix credit scores higher than 800**"""

data[['Credit Score']].show()

# Adjust the Credit Score column
data.where(f.col("Credit Score") > 800).show()

def adjust_CS(x):
  return (x / 10)

data = data.withColumn("Credit Score", f.when(data['Credit Score'] > 800, adjust_CS(data['Credit Score'])))

data.groupby("Credit Score").count().show()

"""# **Imputing Credit Score and Annual Income**"""

avg_CS = np.round(data.agg(f.avg(f.col("Credit Score"))).collect()[0]["avg(Credit Score)"])
avg_CS

# Impute Credit Score
data = data.fillna(avg_CS, subset=["Credit Score"])

data.schema['Loan ID'].dataType

# Obtain the median for Annual Income
med_AI = np.round(data.agg(f.median(f.col("Annual Income"))).collect()[0]["median(Annual Income)"])
med_AI

# Impute Annual Income
data = data.fillna(med_AI, subset = ["Annual Income"])

"""# **Handle bad values in Current Loan Amount**"""

# Get value counts of Current Loan Amount
data.groupby('Current Loan Amount').count().sort('Current Loan Amount', ascending = False).show()

# Get 99999999 methodically instead of trying to hard-code it
extreme_value = data.groupby('Current Loan Amount').count().sort('Current Loan Amount', ascending = False).collect()[0]['Current Loan Amount']

CLA_no_extremes = data.filter(data['Current Loan Amount'] != extreme_value)

CLA_no_extremes.show()

CLA_no_extremes_df = CLA_no_extremes.groupby('Current Loan Amount').count().sort('Current Loan Amount', ascending = False)

CLA_no_extremes_df.groupby('Current Loan Amount').count().sort('Current Loan Amount', ascending = False).show()

median_CLA = CLA_no_extremes_df.agg(f.median(f.col("Current Loan Amount"))).collect()[0]["median(Current Loan Amount)"]

data = data.withColumn("Current Loan Amount", f.when(data["Current Loan Amount"] == extreme_value, median_CLA).otherwise(data["Current Loan Amount"]))

data.groupby("Current Loan Amount").count().sort("Current Loan Amount", ascending = False).show()

"""# **Ensure proper data types**"""

# Let's fix the values in Bankruptcies column
data.groupby('Bankruptcies').count().sort('count', ascending = False).show()

# Impute by 0
data = data.withColumn("Bankruptcies", f.when(data['Bankruptcies'] == "NA", 0).otherwise(data['Bankruptcies']))

# Fix Months Since Last Delinquency since there are some nulls
data.groupby('Months Since Last Delinquency').count().sort('Months Since Last Delinquency', ascending = False).show()

avg_MSLD = np.round(data.agg(f.avg(f.col("Months Since Last Delinquency"))).collect()[0]["avg(Months Since Last Delinquency)"])

avg_MSLD

# Impute by average MSLD
data = data.withColumn("Months Since Last Delinquency", f.when(data['Months Since Last Delinquency'] == "NA", avg_MSLD).otherwise(data['Months Since Last Delinquency']))

data.groupby('Months Since Last Delinquency').count().sort('count', ascending = False).show()

# Set values to integer type
data = data.withColumn("Months Since Last Delinquency", data["Months Since Last Delinquency"].cast(IntegerType()))

"""# **Add Credit utilization as a feature**"""

data.show()

data = data.withColumn("Credit Utilization", f.col("Current Credit Balance") / f.col("Maximum Open Credit"))

"""# **Add Credit as a percentage of annual income as a feature**"""

data = data.withColumn("Credit to Annual Income Ratio", f.col("Current Credit Balance") / f.col("Annual Income"))

"""# **Misc Code**"""

#for c in data.columns:
  #if data.schema[c].dataType != "StringType()":
    #mean = data.agg(f.avg(f.col(c)).alias('avg')).collect()[0]['avg']
    #data = data.na.fill(mean)

# data.agg(f.avg(f.col('Years of Credit History')).alias('avg')).collect()[0]['avg']

# f.isnull(f.col('Loan ID'))

# data.agg(f.avg(f.col("Years of Credit History"))).collect()[0]["avg(Years of Credit History)"]

# data.agg(f.avg(f.col("Years of Credit History")).alias('avg')).collect()[0]["avg"]